{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://user-images.githubusercontent.com/16547060/33613066-e403539c-d9d3-11e7-9501-cbdce2655871.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why am I listening to this weirdo?\n",
    "\n",
    "\n",
    "First thing first, some quick words on your bearded speaker.\n",
    "I am Michele \"Ubik\" De Simoni, I currently work at Bit Bang SRL. as a Junior Data Architect/Data Engineer, I have recently obtained the Google Certified Professional Data Engineer certification, I am one of the manager of the GDG Bologna and most importantly for you, I am a self-taught Pythonista and if you are here listening to me I can safely guess you want to be one too. I have learnt everything I know from free open online material, wisdom and experience freely handed down by others. This is me trying to repaying the debt.\n",
    "You can reach me at either one of these contacts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Contacts:**\n",
    "\n",
    "<i class=\"fa fa-twitter-square fa-1x\" aria-hidden=\"true\"></i> Twitter: [**@mr_ubik**](https://twitter.com/mr_ubik/)\n",
    "\n",
    "<i class=\"fa fa-linkedin-square fa-1x\" aria-hidden=\"true\"></i> Linkedin: [**@mr_ubik**](https://twitter.com/mr_ubik/)\n",
    "\n",
    "<i class=\"fa fa-reddit-square fa-1x\" aria-hidden=\"true\"></i> Reddit: [**@mr_ubik**](https://twitter.com/mr_ubik/)\n",
    "\n",
    "<i class=\"fa fa-github-square fa-1x\" aria-hidden=\"true\"></i> GitHub: [**@mr-ubik**](https://github.com/mr-ubik)\n",
    "\n",
    "<i class=\"fa fa-envelope-square\" aria-hidden=\"true\"></i> Mail: ubik@ubik.tech\n",
    "\n",
    "I also write irregularly for a technical blog where I do actively maintain a list of Python and Programming resources:\n",
    "- http://essays.ubik.tech/\n",
    "- http://essays.ubik.tech/pages/pythonis-index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "In this talk we will briefly cover the key elements that make Python stands out among the other programming languages and also cover the basis of its core data structures.\n",
    "\n",
    "- **Machine Learning**\n",
    "    1. Don't believe the hype\n",
    "    2. GG EZ\n",
    "    3. The Data Jedi Path\n",
    "    \n",
    "\n",
    "- **Python: Learning to love Snakes**\n",
    "    1. General overwiew of the language\n",
    "    2. Pythonic Syntax and Style\n",
    "    3. Pythonic Objects\n",
    "    4. Control Flow\n",
    "    6. Functions\n",
    "    7. Libraries\n",
    "\n",
    "    \n",
    "- **Use Python Luke!**\n",
    "    1. Royal Rumble\n",
    "    2. The Python Ecosystem\n",
    "    3. Data Plumbing\n",
    "    4. Data Porn\n",
    "    5. This is not even my final form\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Don't believe the hype\n",
    "\n",
    "![](https://filmphage.files.wordpress.com/2012/07/raptor-hype.jpg)\n",
    "\n",
    "> Machine learning is a field of computer science that gives computers the ability to learn without being explicitly programmed \n",
    "\n",
    "Today more than ever we are being constantly reminded that machines are coming for our jobs, that our cities are becoming self organizing smart digital hub, our cars are going becoming capable of driving without us, AI diagnosing cancer better than expert doctor, the sky seems the limit. \n",
    "\n",
    "Machine learning is probably one of the hottest topic right now, and for good reasons. The prodigal son of computer science, Machine Learning / AI has not been so much in vogue outside academic circle until the mid 2010s where improvements in data collection, algorithm design, parallelization and raw increase in CPUs and GPUs performance made Machine Learning great again.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# GG EZ\n",
    "\n",
    "> GGEZ\n",
    ">\n",
    "> A phrase used as a taunt at the end of a match in competitive online gaming. It is a contraction of gg and ez.\n",
    "\n",
    "Machine Learning is easy, we need to follow just 7 simple steps:\n",
    "1. Gathering data\n",
    "2. Preparing that data\n",
    "3. Choosing a model\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Hyperparameter tuning\n",
    "7. Prediction.\n",
    "\n",
    "Easy. We can do it in just 53 lines of Pyhton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.2461 - acc: 0.9244 - val_loss: 0.1059 - val_acc: 0.9670\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1012 - acc: 0.9687 - val_loss: 0.0893 - val_acc: 0.9727\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0749 - acc: 0.9770 - val_loss: 0.0879 - val_acc: 0.9772\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0602 - acc: 0.9815 - val_loss: 0.0917 - val_acc: 0.9763\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0520 - acc: 0.9847 - val_loss: 0.0826 - val_acc: 0.9798\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0441 - acc: 0.9870 - val_loss: 0.0767 - val_acc: 0.9832\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0366 - acc: 0.9896 - val_loss: 0.0900 - val_acc: 0.9820\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0830 - val_acc: 0.9830\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0321 - acc: 0.9905 - val_loss: 0.0831 - val_acc: 0.9823\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0289 - acc: 0.9916 - val_loss: 0.0888 - val_acc: 0.9820\n",
      "Test loss: 0.0887690361981\n",
      "Test accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    log_dir='./Graph', histogram_freq=0, batch_size=32, write_graph=True,\n",
    "    write_grads=False, write_images=False, embeddings_freq=0,\n",
    "    embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tbCallBack])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The path to become a Data Jedi\n",
    "\n",
    "Easy right? Well maybe. \n",
    "The code is easily explained, the math can be learned, what's missing from all the nice introductory examples is that they fail to emphasize that machine learning is usually the penultimate step in the **Data \\* ** workflow or what I will refer to as the Data Jedi path. \n",
    "\n",
    "A *Data Jedi* is simply someone who is either learning or practicing one of the following activities. I prefer more neutral term like Data Jedi or Data Ninja rather then the boring old definitions of the disciplines, more often than not you need to be versatile and willing to step out of your element in order to master something new.\n",
    "\n",
    "![](https://d3ansictanv2wj.cloudfront.net/data-science-workflow-example-7666e5329b0fb5498b9afc0b522e73fa.jpg)\n",
    "\n",
    "As you can see it is quite the lengthy process and to truly master it one has to achieve dominance over an increasing number of different fields.\n",
    "\n",
    "While this feat in itself is nigh impossible and pointless, having a working knowledge of all the moving parts of the Data Jedi Path is fundamentals if we wish to master the way of the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python: Learning to Love Snakes\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/python.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://i0.kym-cdn.com/photos/images/original/000/286/479/3c2.jpg)\n",
    "\n",
    "# Learning Python for fun and profit\n",
    "\n",
    "Let's get this out of the way. Everyone interested in programming/computer science should learn Python, the reason is simple: \n",
    "\n",
    "**P Y T H O N** \n",
    "\n",
    "**I S**\n",
    "\n",
    "**A W E S O M E**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python offers an easy path to the mastery of almost any aspect of the programming world, from simple scripts to embedded systems to complex web architectures and artificial intelligence, this language has everything covered. Python is the ultimate swiss army knife of programming languages. It is often the first tier choice for almost any task and when it is not you can easily bet on it being the number 2 or 3 choice. This makes learning (and teaching) it to newcomers a no-brainer (and that is why you see many universities starting to shift from Java to Python (or Javascript, the only other language I would award of my versatility badge)), once the basis are covered you can quickly ramp up to more complex tasks. The language has been growing steadily for the past 20 years, it has no intention to stop and while adoption accelerates, the community surrounding it becomes larger and more vibrant, propelling development of the core language and its libraries in a virtuos circle, so virtuos that just from 2016 to 2017 Python jumped from 4th place to 1st in StackOverflow Developer Survey Most Wanted Language category. There's also an ever increasing demand for Python Developers and becoming a Pythonista may be one of the most profitable decision you can make right now. Having said that let's dive right into the awesomeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Of Python and Pythonistas\n",
    "\n",
    "![](http://s2.quickmeme.com/img/c1/c18763cc00aaebf5ca42bbb5b88922b9ab4fd759e06ae3f1b8b460151eaf0f94.jpg)\n",
    "\n",
    "Python is a general purpose, multi paradigm, dynamically typed, interpreted programming language. That is not a bunch of buzzwordy nonsense. I swear.\n",
    "\n",
    "**Pythonista** is the technical term with which we regard enlightened programmers having chosen to embrace our Lord and Saviour Python, I hope you will join us under the guide of the Benevolent Dictator For Life Guido van Rossum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Multi paradigm --> Imperative, Functional, Object Oriented, Procedural\n",
    "- Languages like Java, C++, C, Rust and Go all are statically typed, meaning types are checked at compile time, Python skipping an explicit compile phase has its types checked only at runtime. This trades earlier bugs detection and performance for ease of use. NOTE: Python, via its library can reach incredible speed and/or support static typing.\n",
    "- > An interpreted language is a programming language for which most of its implementations execute instructions directly and freely, without previously compiling a program into machine-language instructions. The interpreter executes the program directly, translating each statement into a sequence of one or more subroutines already compiled into 0machine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# The Zen of Python\n",
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pythonic Style\n",
    "\n",
    "![](http://s2.quickmeme.com/img/dd/dd6c809714a2f1300a5257ac081d6ab0119da35d5e195acba939472a0b94fa7d.jpg)\n",
    "\n",
    "Style matters. Both in real life and programming. The syntax of language is an user interface, as such it should be optimized for ease of use, clarity, ease of typing and most important of all, readability. Python syntax style is quite rigid, however this rigidness comes as a way to enforce a set of good code writing practices onto everyone, this makes it really ease to read and write. Its most notable features are the use of whitespace, which is actively read by the compiler, and PEP 8 which is the default collection of the \"Pythonic\" default style. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Whitespace and Indention\n",
    "\n",
    "In Python whitespaces and indention matter. A LOT. In breaking with the tradition of other programming languages, Python compiler does actively compile both whitespace and indention. Code breaks when you forget to indent. While slightly annoying at first, this feature alone makes Python one of the easiest language to read and write since you do not need to wrap thing in `{`, `;` and the like of them while being forced to write code in a sane way.\n",
    "\n",
    "![This would never even remotely compile](http://www.digitalcraft.org/iloveyou/images/code/C_BANKS.gif \"DO NOT EVER TRY THIS AT HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Indention, replacing other logical markers, is crucial to the syntax since it establish parent-child operations inside logically nested operations.\n",
    "\n",
    "reality_is_a_simulation = 1\n",
    "other_global_variable = \"This Is a String!\"\n",
    "\n",
    "def pick_a_random_number(random_argument_LOL):\n",
    "    a_local_variable = \"Only the best organically grown local variables!\"\n",
    "    for element in random_argument_LOL:\n",
    "        if reality_is_a_simulation:\n",
    "            print(\"42\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PEP (**P**ython **E**nhancement **P**roposal)\n",
    "\n",
    "> PEP stands for Python Enhancement Proposal. A PEP is a design document providing information to the Python community, or describing a new feature for Python or its processes or environment. The PEP should provide a concise technical specification of the feature and a rationale for the feature.\n",
    "\n",
    "> We intend PEPs to be the primary mechanisms for proposing major new features, for collecting community input on an issue, and for documenting the design decisions that have gone into Python. The PEP author is responsible for building consensus within the community and documenting dissenting opinions.\n",
    "\n",
    "> Because the PEPs are maintained as text files in a versioned repository, their revision history is the historical record of the feature proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PEP 8\n",
    "\n",
    "Among the many PEP, one of the most important is PEP 8 which describes how the \"default\" style rules one should adhere to. The nice thing about PEP 8 is that most editors out there either support it directly or have plugins you can install that will automatically check your code for any failure to comply. PEP 8 while being the most diffuse style is not the only one (i.e. Google Python Style) you should be trying as much to adhere to it whenever it is reasonable to do so. Do not fail however to follow the best advice inside PEP 8:\n",
    "\n",
    "> A Foolish Consistency is the Hobgoblin of Little Minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pythonic Objects\n",
    "\n",
    "Looks are important but in the end we are for the substance. Due to our time constraint I will be able only to give you a small glimpse into the fundamental structures of the language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strings Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG\n",
      "Look mum, no need to declare the type of the variable\n",
      "\n",
      "Look mum, \n",
      "I can even multiline \n",
      "yeeee\n",
      "\n",
      "fish bread\n",
      "fish bread fish bread fish bread fish bread fish bread \n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = 'OMG'\n",
    "string_2 = \"Look mum, no need to declare the type of the variable\"\n",
    "string_3 = \"\"\"\n",
    "Look mum, \n",
    "I can even multiline \n",
    "yeeee\n",
    "\"\"\"\n",
    "string_4 = \"fish\" + \" \" + \"bread\"\n",
    "string_5 = (string_4 + \" \") * 5\n",
    "\n",
    "\n",
    "print(string + \"\\n\" + string_2 + \"\\n\" + string_3 + \"\\n\" + string_4 + \"\\n\" + string_5 +\"\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python as a calculator\n",
    "\n",
    "Python has support for all major arithmetical operations by default, if your needs are more complex there's a multitude of packages that enables way more complicate operations (Python is the defacto go to language for machine learning and scientific computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "integer = 666\n",
    "floating = 3.14  # <-- division between integers always return a float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logical Python\n",
    "\n",
    "As all programming languages, Python has a False and a True boolean value. The useful thing to know is this:\n",
    "\n",
    "```python\n",
    "boolean_0 = False\n",
    "boolean_1 = True\n",
    "\n",
    "\n",
    "bool(1) -> True\n",
    "bool(2) -> True\n",
    "bool(0) -> False\n",
    "bool(None) -> False\n",
    "bool(\"Content\") -> True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DISCLAIMER\n",
    "I shamefully copied and pasted the following sections for Lists, Tuples and Dictionaries from \"Data Science from Scratch\". It is an amazing book especially if you want to get into Data Science. Its section on Lists, Tuples and Dictionaries. It presents data structures in a simple, compact yet meaningful way. Highly recommended reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lists\n",
    "\n",
    "\n",
    "Lists\n",
    "Probably the most fundamental data structure in Python is the list. A list is simply an ordered collection. (It is similar to what in other languages might be called an array, but with some added functionality.)\n",
    "```python\n",
    "integer_list = [1, 2, 3]\n",
    "heterogeneous_list = [\"string\", 0.1, True]\n",
    "list_of_lists = [ integer_list, heterogeneous_list, [] ]\n",
    "list_length = len(integer_list) # equals 3\n",
    "list_sum = sum(integer_list) # equals 6\n",
    "```\n",
    "You can get or set the nth element of a list with square brackets:\n",
    "```python\n",
    "x = range(10) # is the list [0, 1, ..., 9]\n",
    "zero = x[0] # equals 0, lists are 0-indexed\n",
    "one = x[1] # equals 1\n",
    "nine = x[-1] # equals 9, 'Pythonic' for last element\n",
    "eight = x[-2] # equals 8, 'Pythonic' for next-to-last element\n",
    "x[0] = -1 # now x is [-1, 1, 2, 3, ..., 9]\n",
    "```\n",
    "You can also use square brackets to “slice” lists:\n",
    "```python\n",
    "first_three = x[:3] # [-1, 1, 2]\n",
    "three_to_end = x[3:] # [3, 4, ..., 9]\n",
    "one_to_four = x[1:5] # [1, 2, 3, 4]\n",
    "last_three = x[-3:] # [7, 8, 9]\n",
    "without_first_and_last = x[1:-1] # [1, 2, ..., 8]\n",
    "copy_of_x = x[:] # [-1, 1, 2, ..., 9]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python has an in operator to check for list membership:\n",
    "```python\n",
    "1 in [1, 2, 3] # True\n",
    "0 in [1, 2, 3] # False\n",
    "```\n",
    "This check involves examining the elements of the list one at a time, which means\n",
    "that you probably shouldn’t use it unless you know your list is pretty small (or unless\n",
    "you don’t care how long the check takes).\n",
    "It is easy to concatenate lists together:\n",
    "```python\n",
    "x = [1, 2, 3]\n",
    "x.extend([4, 5, 6]) # x is now [1,2,3,4,5,6]\n",
    "```\n",
    "If you don’t want to modify x you can use list addition:\n",
    "```python\n",
    "x = [1, 2, 3]\n",
    "y = x + [4, 5, 6] # y is [1, 2, 3, 4, 5, 6]; x is unchanged\n",
    "```\n",
    "More frequently we will append to lists one item at a time:\n",
    "```python\n",
    "x = [1, 2, 3]\n",
    "x.append(0) # x is now [1, 2, 3, 0]\n",
    "y = x[-1] # equals 0\n",
    "z = len(x) # equals 4\n",
    "```\n",
    "It is often convenient to unpack lists if you know how many elements they contain:\n",
    "```python\n",
    "x, y = [1, 2] # now x is 1, y is 2\n",
    "```\n",
    "although you will get a ValueError if you don’t have the same numbers of elements\n",
    "on both sides.\n",
    "It’s common to use an underscore for a value you’re going to throw away:\n",
    "_, y = [1, 2] # now y == 2, didn't care about the first element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuples\n",
    "Tuples are lists’ immutable cousins. Pretty much anything you can do to a list that\n",
    "doesn’t involve modifying it, you can do to a tuple. You specify a tuple by using\n",
    "parentheses (or nothing) instead of square brackets:\n",
    "```python\n",
    "my_list = [1, 2]\n",
    "my_tuple = (1, 2)\n",
    "other_tuple = 3, 4\n",
    "my_list[1] = 3 # my_list is now [1, 3]\n",
    "try:\n",
    "    my_tuple[1] = 3\n",
    "except TypeError:\n",
    "    print \"cannot modify a tuple\"\n",
    "```\n",
    "Tuples are a convenient way to return multiple values from functions:\n",
    "```python\n",
    "def sum_and_product(x, y):\n",
    "    return (x + y),(x * y)\n",
    "sp = sum_and_product(2, 3) # equals (5, 6)\n",
    "s, p = sum_and_product(5, 10) # s is 15, p is 50\n",
    "```\n",
    "Tuples (and lists) can also be used for multiple assignment:\n",
    "```python\n",
    "x, y = 1, 2 # now x is 1, y is 2\n",
    "x, y = y, x # Pythonic way to swap variables; now x is 2, y is 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dictionaries \n",
    "Another fundamental data structure is a dictionary, which associates values with keys\n",
    "and allows you to quickly retrieve the value corresponding to a given key:\n",
    "```python\n",
    "empty_dict = {} # Pythonic\n",
    "empty_dict2 = dict() # less Pythonic\n",
    "grades = { \"Joel\" : 80, \"Tim\" : 95 } # dictionary literal\n",
    "```\n",
    "You can look up the value for a key using square brackets:\n",
    "```python\n",
    "joels_grade = grades[\"Joel\"] # equals 80\n",
    "```\n",
    "But you’ll get a KeyError if you ask for a key that’s not in the dictionary:\n",
    "```python\n",
    "try:\n",
    "    kates_grade = grades[\"Kate\"]\n",
    "except KeyError:\n",
    "    print(\"no grade for Kate!\")\n",
    "```\n",
    "You can check for the existence of a key using in:\n",
    "```python\n",
    "joel_has_grade = \"Joel\" in grades # True\n",
    "kate_has_grade = \"Kate\" in grades # False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dictionaries have a get method that returns a default value (instead of raising an\n",
    "exception) when you look up a key that’s not in the dictionary:\n",
    "```python\n",
    "joels_grade = grades.get(\"Joel\", 0) # equals 80\n",
    "kates_grade = grades.get(\"Kate\", 0) # equals 0\n",
    "no_ones_grade = grades.get(\"No One\") # default default is None\n",
    "```\n",
    "You assign key-value pairs using the same square brackets:\n",
    "```python\n",
    "grades[\"Tim\"] = 99 # replaces the old value\n",
    "grades[\"Kate\"] = 100 # adds a third entry\n",
    "num_students = len(grades) # equals 3\n",
    "```\n",
    "We will frequently use dictionaries as a simple way to represent structured data:\n",
    "```python\n",
    "tweet = {\n",
    "    \"user\" : \"joelgrus\",\n",
    "    \"text\" : \"Data Science is Awesome\",\n",
    "    \"retweet_count\" : 100,\n",
    "    \"hashtags\" : [\"#data\", \"#science\", \"#datascience\", \"#awesome\", \"#yolo\"]\n",
    "}\n",
    "```\n",
    "Besides looking for specific keys we can look at all of them:\n",
    "```python\n",
    "tweet_keys = tweet.keys() # list of keys\n",
    "tweet_values = tweet.values() # list of values\n",
    "tweet_items = tweet.items() # list of (key, value) tuples\n",
    "\"user\" in tweet_keys # True, but uses a slow list in\n",
    "\"user\" in tweet # more Pythonic, uses faster dict in\n",
    "\"joelgrus\" in tweet_values # True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dictionary keys must be immutable; in particular, you cannot use lists as keys. If\n",
    "you need a multipart key, you should use a tuple or figure out a way to turn the key\n",
    "into a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The code must flow\n",
    "\n",
    "Control flow is crucial for any programming language: Python does this in a simple, effective way. We have five keywords controlling our flow, the only catch is to remember to put `:` at the end of the line in which our keyword appears. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# if elif else\n",
    "```python\n",
    "if what_is_here_on_the_right_is_true:\n",
    "    do_something()\n",
    "elif if_the_previous_step_failed_and_this_is_true:\n",
    "    do_something_else()\n",
    "if what_is_here_on_the_right_is_true:\n",
    "    do_something()\n",
    "elif if_the_previous_step_failed_and_this_is_true:\n",
    "    do_something_else()\n",
    "else:  # Python will valuate this only if every other steps before failed\n",
    "    do_something_else()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# for\n",
    "\n",
    "The `for` is used with iterable, object like list, tuple, strings and dictionaries are all iterable offering you the possibility to loop through their items.\n",
    "\n",
    "```python\n",
    "fibonacci = [ 1, 1, 2, 3, 5, 8, 13]\n",
    "for n in fibonacci:\n",
    "    do_something()\n",
    "```\n",
    "\n",
    "The do_something() function will be iterated for each element in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# while + (break)\n",
    "\n",
    "`while` is used to create a loop that goes on as long as the condition after `while` is `True` OR `break` has been called. A classic example  of an infinite `while` + `break`:\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    repeat_this_action()\n",
    "    if this_is_true_the_loop_will_ends:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Functions\n",
    "\n",
    "Function, in a way similar to mathematics, is a rule established between 0 or more objects and returning (with a `return`) a corresponding output. In python a function is defined using `def`:\n",
    "\n",
    "```python\n",
    "def name_of_the_fucntion(zero_or_more_arguments):\n",
    "    \"\"\"\n",
    "    Docstring describing what the function does\n",
    "    \"\"\"\n",
    "    something_something = blablabla\n",
    "    return something_something\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.redd.it/00824ycw3hwy.jpg)\n",
    "\n",
    "# The Standard Library and PyPi\n",
    "\n",
    "One of the strength of the language is the infinite amount of libraries available for it. The first stop is the Standard Library, it comes bundled with every Python installation spanning a very wide spectrum of use-cases. \n",
    "\n",
    "The real star here is the Python Packages Index, with its small **1 2 2 6 3 8** packages. If you need it, chances are you can find it.\n",
    "\n",
    "# PIP\n",
    "\n",
    "Installing a package is as easy as typing `pip install name_of_the_package` however there's more to it as you may pollute your default Python installation.\n",
    "\n",
    "# `import`\n",
    "\n",
    "Once a package is installed you can easily use it by calling `import`\n",
    "\n",
    "```python\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from google.cloud import BigQuery\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://s-media-cache-ak0.pinimg.com/originals/51/fc/f1/51fcf1c55a37b5544ad6fe40f3765cf0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Python Luke\n",
    "\n",
    "Python with its ease of use and clarity conquered the heart of many programmers, this meant that a lot of people started porting libraries from other languages, their motives varied but the end result was the same: the Python Ecosystem became richer and richer, this has been True for the Scientific Computing and Data_* fields as well.\n",
    "***\n",
    "Starting with Numpy and then Matplotlib, \"stolen\" from Matlab, to Pandas and its Data Frame which is clearly the Python equivalent of the R Dataframe, the Python Data community built an impressive stack of tools on top of these libraries, some of them, like Scikit-Learn (which is probably the most used non-deep Machine Learning library) stand out as example of excellent open source, community driven project and amazing case-study for API designers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Royal Rumble or how to chooose a Data Jedi\n",
    "\n",
    "## Python\n",
    "Versatility, clear APIs, speed, reliability, readability, huge community and tools are the core motivations that should push an aspiring Data Science to choose Python over other programming languages. This is the only one language that will let you walk the Data Jedi Path without needing any integrations whatsoever by other, however I recommend taking at least one of the following as a companion to Python as this will amplify their powers beyond measure.\n",
    "\n",
    "**Legend:** <font color=purple>Purple</font> > <font color=blue>Blue</font> > <font color=green>Green</font> > <font color=black>Black</font> > <font color=red>Red</font>.\n",
    "***\n",
    "## C, C++, Fortran\n",
    "Where you need to squeeze every little bit of performance you will find low level languages. Their syntax, package and dependencies management is horrible, they do not certainly hold your hands but they offer you access to the rawest power of them all, **THE BARE METAL**. Developers' time is usually way costlier than compute time, thus the shift towards easier, \"slower\" programming languages. Thus said, if you want to help in the development of the underlying engine of Python or its data libraries you need to pick one of these up. **C** is my recommended choice, being at the base of the Python Interpreter and Numpy.\n",
    "***\n",
    "## Java\n",
    "Portable, reliable, freed from any platform constraints Java was for a long time a good choice. While I joke and laugh about the ugliness and verbosity of the syntax, I have the uttermost respect for the heavy duty that this behemoth has done (and continues to do). There many libraries and projects which offers support for Java, but as said the syntax kills it by making fast rapid iterations and readability its Achilles heel. There's hope, and that hope is **KOTLIN**, still if you need to data science using the JVM look at Scala.\n",
    "***\n",
    "## Javascript\n",
    "What??? Javascript?? Yep, you are not dreaming. Javascript is the best language for the born-again aesthete Data Jedi. More and more data-relevant libraries offers Javascript APIs but most importantly all the coolest visualizations are done via JS libraries, usually sitting on top of D3.js **THE** undiscussed god-emperor of interactive visualizations. More artist and designer than data plumber or mad scientist, the Javascript Data Aesthete can render even the dumbest dataset a work of art. Also Javascript is with HTML and CSS the backbone of the modern web experience, the most used, popular, and versatile language in the world, can either substitute Python if one wants to specialize in the data-designing part or complement it forming the ultimate combination in terms of versatility and pool of possible job positions.\n",
    "***\n",
    "## Julia\n",
    "The new kid on the block, Julia is to me more like a modern take on the R concept, capable of attracting an increasing community, it offers speed, readability and ease of analysis all in one package. It is for sure interesting although being in its infancy makes support for multiple workflows and libraries scarce at times.\n",
    "***\n",
    "## R\n",
    "A nice syntax, a built-in dataframe, a plethora of great packages and a great IDE in the form of R-Studio made R the long-time king of Data Science and Statistical analysis. Python stole the fire of the Dataframe from the Gods and with Jupyter also established a better platform/technology for the interactive analysis/exploration. A way larger community coupled with the rise of Jupyter, Scikit-Learn and Tensorflow made Python slightly more popular than R for these tasks. Mostly used by statisticians, biologists and widely taught at both undergraduate and graduate level, R is still a force to be reckoned with, especially when it comes to quick exploratory analysis. My advice is to learn Python first and R secondly, you do not necessarily need one if you have the other but together they voltron into a new whole degree of awesome.\n",
    "***\n",
    "## Scala\n",
    "Functional programming on the JVM has never been cooler than now since living in the age of Big Data means sooner or later having to deal with distributed parallel computing and that means considering Spark. Python having picked up proper support for functional programming with Coconut and having built PySpark can make Scala a little redundant. However if you plan on specializing in the use of Spark and its ecosystem or on being mind blown by the trip inducing functional style Scala is the language for you. Coursera currently has the best MOOC on functional programming and Scala, once you are ready to have your mind challenged and your horizon expanded go and look up a functional programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://raw.githubusercontent.com/jupyter/design/master/logos/Rectangle%20Logo/rectanglelogo-greytext-orangebody-greymoons/rectanglelogo-greytext-orangebody-greymoons.png)\n",
    "\n",
    "# Use Jupyter Luke!\n",
    "\n",
    "We have already mentioned it several times by now but Jupyter has been taking the Scientific Community by storm.\n",
    "\n",
    "> The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n",
    "\n",
    "Evolved from the IPython project, it gathered enough momentum and was able to reorganize itself into a language-agnostic platform that has become the defacto new standard for most Data and Scientific tasks. In order to fully appreciate its magic you have to try it. Soon a new iteration of the Jupyter Notebook, called **Jupyter Lab** will be released and it promises to be more revolutionary than its predecessor.\n",
    "\n",
    "*FUN FACT: all these slides have been created using Jupyter.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://www.quickmeme.com/img/bd/bd8003add79f5d11643d53abc4dc83aeb0c9dbf060a49c0f055cd18ea41909ef.jpg)\n",
    "\n",
    "# Of Pythons and Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Plumbing\n",
    "\n",
    "![](http://planspace.org/2014/01/04/some-theory-and-practice-for-data-cleaning/clean_all_the_data_maybe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Porn\n",
    "![](http://i0.kym-cdn.com/photos/images/original/000/786/165/583.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# All your cores are belong to me: Parallelism and Multithreading in Data_*\n",
    "\n",
    "If you work with data long enough you are bound to encounter two issues: your datasets become too large for your puny RAM and/or you need to go from single threaded/process to multi-threaded/process code. \n",
    "\n",
    "How do you go from here to there?\n",
    "\n",
    "Easy, just write multi-threaded Python. \n",
    "\n",
    "![](https://img.devrant.com/devrant/rant/r_122450_BmYCG.jpg)\n",
    "\n",
    "I was kidding. *One does not simply write multi-threaded code*. For the sake of the discussion let's just assume two things:\n",
    "\n",
    "1. Writing multithreaded code is hard.\n",
    "2. Since you are not the first encountering this problem, odds are a solution exists out there.\n",
    "\n",
    "Indeed there's not one but TWO easy(ish) solutions you can adopt today in order to make your code scale across thousands of core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask: Multithreaded Numpy/Pandas\n",
    "\n",
    "![](http://i0.kym-cdn.com/photos/images/newsfeed/000/386/280/bd8.png)\n",
    "\n",
    "Did you think Numpy could not evolve beyond Pandas? You fool.\n",
    "\n",
    "**Dask** is Pandas on steroids: whereas Numpy and Pandas are limited by their signgle-threaded nature, Dask distributes the arrays/dataframes over all your threads/cores locally or on multiple machines, while mirroring Pandas API so you do not have to learn it again. In 99% of use cases you can convert your Pandas code to Dask code in 1:1 basis. \n",
    "\n",
    "You should use Dask whenever your data are in the sub-terabyte space and/or you plan on exploiting only (all)the cores+RAM of one (possibly powerful) machines.\n",
    "\n",
    "If your need goes beyond that, you should start looking at the all-time star of distributed computing: **SPARK**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- [You can find all the resources you may need on my site, divided by topic and level. 😎]()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python3-gdg",
   "language": "python",
   "name": "python3-gdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
